{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/chandlertimm/manga-colorization-training?scriptVersionId=96813749\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport random\nimport math\nimport re\nimport time\nimport numpy as np\nimport json\nimport cv2\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport scipy\nimport warnings\nimport shutil\nimport random\nimport shutil \n\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom distutils.dir_util import copy_tree","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the dataset","metadata":{}},{"cell_type":"code","source":"if not os.path.isdir('./manga_dataset'):\n    os.makedirs('./manga_dataset')\n    os.makedirs('./manga_dataset/colored/')\n    os.makedirs('./manga_dataset/grayscale/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl_1 = '../input/unified/blackclover/colored/'\ncl_2 = '../input/unified/bukonohero/colored/'\ncl_3 = '../input/unified/onepiece/colored/'\n\ntarget_dir_cl = './manga_dataset/colored/'\n    \nfile_names_cl_1 = os.listdir(cl_1)\nfile_names_cl_2 = os.listdir(cl_2)\nfile_names_cl_3 = os.listdir(cl_3)\n    \nfor file_name in tqdm(file_names_cl_1, 'blackclover colored'):\n    shutil.copy(os.path.join(cl_1, file_name), target_dir_cl)\n    os.rename(os.path.join(target_dir_cl, file_name), os.path.join(target_dir_cl, str('blackclover_cl') + file_name))\n    \nfor file_name in tqdm(file_names_cl_2, 'bukonohero colored'):\n    shutil.copy(os.path.join(cl_2, file_name), target_dir_cl)\n    os.rename(os.path.join(target_dir_cl, file_name), os.path.join(target_dir_cl, str('bukonohero_cl') + file_name))\n    \nfor file_name in tqdm(file_names_cl_3, 'onepiece colored'):\n    shutil.copy(os.path.join(cl_3, file_name), target_dir_cl)\n    os.rename(os.path.join(target_dir_cl, file_name), os.path.join(target_dir_cl, str('onepiece_cl') + file_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bw_1 = '../input/unified/blackclover/grayscale/'\nbw_2 = '../input/unified/bukonohero/grayscale/'\nbw_3 = '../input/unified/onepiece/grayscale/'\n\ntarget_dir_bw = './manga_dataset/grayscale/'\n\nfile_names_bw_1 = os.listdir(bw_1)\nfile_names_bw_2 = os.listdir(bw_2)\nfile_names_bw_3 = os.listdir(bw_3)\n\nfor file_name in tqdm(file_names_bw_1, 'blackclover grayscale'):\n    shutil.copy(os.path.join(bw_1, file_name), target_dir_bw)\n    os.rename(os.path.join(target_dir_bw, file_name), os.path.join(target_dir_bw, str('blackclover_bw') + file_name))\n    \nfor file_name in tqdm(file_names_bw_2, 'bukonohero grayscale'):\n    shutil.copy(os.path.join(bw_2, file_name), target_dir_bw)\n    os.rename(os.path.join(target_dir_bw, file_name), os.path.join(target_dir_bw, str('bukonohero_bw') + file_name))\n    \nfor file_name in tqdm(file_names_bw_3, 'onepiece grayscale'):\n    shutil.copy(os.path.join(bw_3, file_name), target_dir_bw)\n    os.rename(os.path.join(target_dir_bw, file_name), os.path.join(target_dir_bw, str('onepiece_bw') + file_name))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir('./manga_dataset/colored/')))\nprint(len(os.listdir('./manga_dataset/grayscale/')))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# colored\ncolored_files =  os.listdir('./manga_dataset/colored/')\n\n# grayscale\ngrayscale_files =  os.listdir('./manga_dataset/grayscale/')\ngrayscale_files = grayscale_files[:3577]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shuffle the dataset\ntemp = list(zip(colored_files, grayscale_files))\n\nrandom.shuffle(temp)\nres1, res2 = zip(*temp)\n\n# res1 and res2 come out as tuples, and so must be converted to lists.\ncolored, grayscale = list(res1), list(res2)\n\nprint(colored[0:5])\nprint(grayscale[0:5])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split the dataset 0.8 for training\n\n#training colored\ntrain_cl = []\nfor i in tqdm(range(int(0.0*len(colored)), int(0.8*len(colored)))):\n    train_cl.append(colored[i])\n    \n#testing grayscale\ntest_cl = []\nfor i in tqdm(range(int(0.8*len(colored)), int(1.0*len(colored)))):\n    test_cl.append(colored[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_cl[-3:None])\nprint(test_cl[0:3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training grayscale\ntrain_bw = []\nfor i in tqdm(range(int(0.0*len(grayscale)), int(0.8*len(grayscale)))):\n    train_bw.append(grayscale[i])\n    \n#testing grayscale\ntest_bw = []\nfor i in tqdm(range(int(0.8*len(grayscale)), int(1.0*len(grayscale)))):\n    test_bw.append(grayscale[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_bw[-3:None])\nprint(test_bw[0:3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create the dataset folders\nif not os.path.isdir('./train_test'):\n    os.makedirs('./train_test')\n    # unpaired image dataset path\n    os.makedirs('./train_test/trainA/')\n    os.makedirs('./train_test/trainB/')\n    os.makedirs('./train_test/testA/')\n    os.makedirs('./train_test/testB/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find(name, path):\n    for root, dirs, files in os.walk(path):\n        if name in files:\n            return os.path.join(root, name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy the train dataset to unpaired image dataset path\nfor i in tqdm(range(len(train_cl)), 'copying train colored and grayscale'):\n    # Source path \n    src1 = find(str(train_bw[i]), './manga_dataset/grayscale/')\n    src2 = find(str(train_cl[i]), './manga_dataset/colored/')\n\n    # Destination path \n    dest1 = './train_test/trainA/'\n    dest2 = './train_test/trainB/'\n\n    # Copy the content of source to destination \n    shutil.copy(src1, dest1) \n    shutil.copy(src2, dest2)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy the test dataset to unpaired image dataset path\nfor i in tqdm(range(len(test_cl)), 'copying test colored and grayscale'):\n    # Source path \n    src1 = find(str(test_bw[i]), './manga_dataset/grayscale/')\n    src2 = find(str(test_cl[i]), './manga_dataset/colored/')\n\n    # Destination path \n    dest1 = './train_test/testA/'\n    dest2 = './train_test/testB/'\n\n    # Copy the content of source to destination \n    shutil.copy(src1, dest1) \n    shutil.copy(src2, dest2) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Install MMGeneration","metadata":{}},{"cell_type":"code","source":"# Check nvcc version\n!nvcc -V\n# Check GCC version\n!gcc --version\n\n# Check Pytorch installation\nimport torch\nprint(torch.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m pip install --upgrade pip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda install pytorch==1.6.0 torchvision==0.7.0 cudatoolkit=10.1 -c pytorch -y\n\n# install the latest mmcv\n# pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/{cu_version}/{torch_version}/index.html\n!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.6.0/index.html\n\n# install mmgeneration\n!rm -rf mmgeneration\n!git clone https://github.com/open-mmlab/mmgeneration.git\n%cd mmgeneration\n!pip install -r requirements.txt\n!pip install -v -e .","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmcv import collect_env\ncollect_env()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check MMDetection installation\nimport mmgen\nprint(mmgen.__version__)\n\n# Check mmcv installation\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start training","metadata":{}},{"cell_type":"code","source":"# download pre-trained cyclegan model in winter2summer dataset\nimport wget\n\nurl = 'https://download.openmmlab.com/mmgen/cyclegan/refactor/cyclegan_lsgan_resnet_in_1x1_246200_summer2winter_convert-bgr_20210902_165932-fcf08dc1.pth'\nwget.download(url, out='../')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile configs/cyclegan/cyclegan_lsgan_resnet_in_summer2winter_b1x1_250k.py\n\n_base_ = [\n    '../_base_/models/cyclegan/cyclegan_lsgan_resnet.py',\n    '../_base_/datasets/unpaired_imgs_256x256.py',\n    '../_base_/default_runtime.py'\n]\n\ndomain_a = 'grayscale'\ndomain_b = 'colored'\nmodel = dict(\n    default_domain=domain_b,\n    reachable_domains=[domain_a, domain_b],\n    related_domains=[domain_a, domain_b],\n    gen_auxiliary_loss=[\n        dict(\n            type='L1Loss',\n            loss_weight=10.0,\n            loss_name='cycle_loss',\n            data_info=dict(\n                pred=f'cycle_{domain_a}', target=f'real_{domain_a}'),\n            reduction='mean'),\n        dict(\n            type='L1Loss',\n            loss_weight=10.0,\n            loss_name='cycle_loss',\n            data_info=dict(\n                pred=f'cycle_{domain_b}',\n                target=f'real_{domain_b}',\n            ),\n            reduction='mean'),\n        dict(\n            type='L1Loss',\n            loss_weight=0.5,\n            loss_name='id_loss',\n            data_info=dict(\n                pred=f'identity_{domain_a}', target=f'real_{domain_a}'),\n            reduction='mean'),\n        dict(\n            type='L1Loss',\n            loss_weight=0.5,\n            loss_name='id_loss',\n            data_info=dict(\n                pred=f'identity_{domain_b}', target=f'real_{domain_b}'),\n            reduction='mean')\n    ])\ndataroot = '.././train_test/'\ntrain_pipeline = [\n    dict(\n        type='LoadImageFromFile',\n        io_backend='disk',\n        key=f'img_{domain_a}',\n        flag='color'),\n    dict(\n        type='LoadImageFromFile',\n        io_backend='disk',\n        key=f'img_{domain_b}',\n        flag='color'),\n    dict(\n        type='Resize',\n        keys=[f'img_{domain_a}', f'img_{domain_b}'],\n        scale=(256, 368),\n        interpolation='bicubic'),\n    dict(\n        type='Crop',\n        keys=[f'img_{domain_a}', f'img_{domain_b}'],\n        crop_size=(368, 256),\n        random_crop=True),\n    dict(type='Flip', keys=[f'img_{domain_a}'], direction='horizontal'),\n    dict(type='Flip', keys=[f'img_{domain_b}'], direction='horizontal'),\n    dict(type='RescaleToZeroOne', keys=[f'img_{domain_a}', f'img_{domain_b}']),\n    dict(\n        type='Normalize',\n        keys=[f'img_{domain_a}', f'img_{domain_b}'],\n        to_rgb=False,\n        mean=[0.5, 0.5, 0.5],\n        std=[0.5, 0.5, 0.5]),\n    dict(type='ImageToTensor', keys=[f'img_{domain_a}', f'img_{domain_b}']),\n    dict(\n        type='Collect',\n        keys=[f'img_{domain_a}', f'img_{domain_b}'],\n        meta_keys=[f'img_{domain_a}_path', f'img_{domain_b}_path'])\n]\n\ntest_pipeline = [\n    dict(\n        type='LoadImageFromFile',\n        io_backend='disk',\n        key=f'img_{domain_a}',\n        flag='color'),\n    dict(\n        type='LoadImageFromFile',\n        io_backend='disk',\n        key=f'img_{domain_b}',\n        flag='color'),\n    dict(\n        type='Resize',\n        keys=[f'img_{domain_a}', f'img_{domain_b}'],\n        scale=(256, 368),\n        interpolation='bicubic'),\n    dict(type='RescaleToZeroOne', keys=[f'img_{domain_a}', f'img_{domain_b}']),\n    dict(\n        type='Normalize',\n        keys=[f'img_{domain_a}', f'img_{domain_b}'],\n        to_rgb=False,\n        mean=[0.5, 0.5, 0.5],\n        std=[0.5, 0.5, 0.5]),\n    dict(type='ImageToTensor', keys=[f'img_{domain_a}', f'img_{domain_b}']),\n    dict(\n        type='Collect',\n        keys=[f'img_{domain_a}', f'img_{domain_b}'],\n        meta_keys=[f'img_{domain_a}_path', f'img_{domain_b}_path'])\n]\n\ndata = dict(\n    train=dict(\n        dataroot=dataroot,\n        pipeline=train_pipeline,\n        domain_a=domain_a,\n        domain_b=domain_b),\n    val=dict(\n        dataroot=dataroot,\n        domain_a=domain_a,\n        domain_b=domain_b,\n        pipeline=test_pipeline),\n    test=dict(\n        dataroot=dataroot,\n        domain_a=domain_a,\n        domain_b=domain_b,\n        pipeline=test_pipeline))\n\noptimizer = dict(\n    generators=dict(type='Adam', lr=0.0002, betas=(0.5, 0.999)),\n    discriminators=dict(type='Adam', lr=0.0002, betas=(0.5, 0.999)))\n\n# learning policy\nlr_config = dict(\n    policy='Linear', by_epoch=False, target_lr=0, start=125000, interval=1250)\n\ncheckpoint_config = dict(interval=5000, save_optimizer=True, by_epoch=False)\ncustom_hooks = [\n    dict(\n        type='MMGenVisualizationHook',\n        output_dir='training_samples',\n        res_name_list=[f'fake_{domain_a}', f'fake_{domain_b}'],\n        interval=5000)\n]\n\nrunner = None\nuse_ddp_wrapper = True\ntotal_iters = 250000\nload_from = '../cyclegan_lsgan_resnet_in_1x1_246200_summer2winter_convert-bgr_20210902_165932-fcf08dc1.pth'\n# resume_from = './work_dirs/cyclegan_bw2cl/ckpt/cyclegan_bw2cl/iter_55000.pth'\nworkflow = [('train', 1)]\nexp_name = 'cyclegan_bw2cl'\nwork_dir = f'./work_dirs/{exp_name}'\n# testA: 716, testB:716\nnum_images = 716\nmetrics = dict(\n    FID=dict(type='FID', num_images=num_images, image_shape=(3, 368, 256)),\n    IS=dict(\n        type='IS',\n        num_images=num_images,\n        image_shape=(3, 368, 256),\n        inception_args=dict(type='pytorch')))\n\nevaluation = dict(\n    type='TranslationEvalHook',\n    target_domain=domain_b,\n    interval=5000,\n    metrics=[\n        dict(type='FID', num_images=num_images, bgr2rgb=True),\n        dict(\n            type='IS',\n            num_images=num_images,\n            inception_args=dict(type='pytorch'))\n    ],\n    best_metric=['fid', 'is'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python tools/train.py configs/cyclegan/cyclegan_lsgan_resnet_in_summer2winter_b1x1_250k.py --work-dir ./work_dirs/cyclegan_bw2cl --no-validate","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}